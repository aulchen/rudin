\documentclass{amsart}
\usepackage{mathtools}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}

\newcommand{\RiemannIntable}{
  \mathfrak{R}
}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\author{Arthur Chen}
\title{Rudin Chapter 6}
\date{\today}

\begin{document}

\section*{6.6 Integration and Differentiation}

\subsection*{Problem 6.R:13}
Let $f(x) = \int_{t=x}^{t=x+1} \sin(t^2)dt$.
\subsubsection*{a}
Show that when $x>0$, $|f(x)| < \frac{1}{x}$. 

\begin{proof}
Note that $x>0$ implies that the limits of integration are correct. Make the substitution $t^2 = u$ to get
\[
f(x) = \frac{1}{2} \int_{u = x^2}^{u = (x+1)^2} u^{-\frac{1}{2}} \sin(u)du
\]

Integrate by parts with $a = u^{\frac{1}{2}}$ and $db = \sin(u)$ to get
\begin{align*}
f(x) &= \frac{1}{2}
\left[
-u^{-\frac{1}{2}}\cos(u)]_{x^2}^{(x+1)^2}
-\frac{1}{2} \int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}} \cos(u)du
\right] \\
&= \frac{\cos(x^2)}{2x} - \frac{\cos((x+1)^2)}{2(x+1)} - \frac{1}{4} \int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}} \cos(u)du
\end{align*}

Evaluating the integral on the right, $\cos(x) \geq -1$, so
\[
\int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}} \cos(u)du
\geq - \int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}} du
= 2 \left(\frac{1}{x+1} - \frac{1}{x} \right)
\]

Substituting,
\begin{align*}
f(x) &\leq \frac{\cos(x^2)}{2x} - \frac{\cos((x+1)^2)}{2(x+1)} - \frac{1}{2(x+1)} + \frac{1}{2x} \\
&= \frac{\cos(x^2) + 1}{2x} - \frac{\cos((x+1)^2) + 1}{2(x+1)} \\
& \leq \frac{2}{2x} = \frac{1}{x}
\end{align*}

Since $\cos(t) \leq 1$. To show that $f(x) \geq -\frac{1}{x}$, it suffices to show that $f(x) \leq \frac{1}{x}$.
\[
-f(x) = \frac{\cos((x+1)^2)}{2(x+1} - \frac{\cos(x^2)}{2x} + \frac{1}{4} \int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}} \cos(u)du
\]

By a similar argument as before, $\cos(x) \leq 1$, so
\[
\int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}} \cos(u)du
\leq \int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}} du
= 2 \left(\frac{1}{x} - \frac{1}{x+1} \right)
\]

Substituting,
\begin{align*}
-f(x) &\leq \frac{\cos((x+1)^2)}{2(x+1} - \frac{\cos(x^2)}{2x} + \frac{1}{2x} - \frac{1}{2(x+1)} \\
&\leq \frac{1}{2(x+1)} + \frac{1}{2x} + \frac{1}{2x} - \frac{1}{2(x+1)} \\
&= \frac{1}{x}
\end{align*}

\end{proof}

\subsubsection*{b}
Prove that there exists constant $c$ and function $r(x)$ with $|r(x)| < \frac{c}{x}$ such that
\[
2xf(x) = \cos(x^2) - \cos((x+1)^2) + r(x)
\]

\begin{proof}
I will assume that $x>0$, as the expression $\frac{c}{x}$ doesn't make much sense for $x = 0$, and it's impossible for $|r(x)| < \frac{c}{x}$ to be true for both positive and negative $x$ while $c$ is constant.

From results in Part a,
\begin{align*}
2xf(x) &= \cos(x^2) - \frac{x}{x+1}\cos((x+1)^2)
- \frac{x}{2} \int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}} \cos(u)du \\
&= \cos(x^2) - \cos((x+1)^2)
+ \frac{1}{x+1}\cos((x+1)^2) - \frac{x}{2} \int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}} \cos(u)du
\end{align*}

From the above, it's clear that $r(x) = \frac{1}{x+1}\cos((x+1)^2) - \frac{x}{2} \int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}} \cos(u)du$. Now it remains to show that $|r(x)| < \frac{c}{x}$. Using that $\cos(t)$ and $-\cos(t)$ is\\are bounded above by $1$,
\[
r(x) \leq \frac{1}{x+1} + \frac{x}{2}\int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}}du
= \frac{1}{x+1} - x\left[\frac{1}{x+1} - \frac{1}{x} \right]
= \frac{2}{x+1} < \frac{2}{x}
\]

Similarly,
\begin{align*}
-r(x) &= -\frac{1}{x+1}\cos((x+1)^2) + \frac{x}{2} \int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}} \cos(u)du \\
&\geq -\frac{1}{x+1} - \frac{x}{2}\int_{x^2}^{(x+1)^2} u^{-\frac{3}{2}}du
= -\frac{2}{x+1} \geq -\frac{2}{x}
\end{align*}

Thus $|r(x)| < \frac{3}{x}$.

\end{proof}

\subsubsection*{c}
Find the upper and lower limits of $xf(x)$ as $x$ approaches infinity.

We know from previous results that
\[
xf(x) = \frac{\cos(x^2))}{2} - \frac{\cos((x+1)^2)}{2} + s(x)
\]
where $|s(x)| \leq \frac{1}{x}$. $\lim_{x\rightarrow\infty} s(x) = 0$, so the upper and lower limits of $s(x)$ are also $0$.

Note that by the periodicity of cosine, for $n \in N$, $\cos(\sqrt{2\pi n}^2) = 1$. We now show that there exist infinite $n \in N$ such that $\cos((\sqrt{2\pi n}+1)^2) = \cos(2\pi n + 2\sqrt{2 \pi n} + 1) = -1$, thus implying that $\limsup_{n\rightarrow\infty} xf(x) = 1$.

\begin{theorem}
\label{NearCosine}
Let $\delta > 0$. Then there exist infinite natural numbers $a$ such that $|2\sqrt{2a\pi} + 1 - \pi| < \delta \left(\mod 2\pi \right)$. In other words, $2\sqrt{2a\pi} + 1$ becomes arbitrarily close to a number of the form $b\pi$, where $b$ is an odd number.
\end{theorem}

To prove this, we will need to analyze the behavior of $g(x) = 2\sqrt{2\pi}\sqrt{x} + 1$, then evaluate it at specifically chosen $a$'s. We first start by analyzing the Taylor series of $\sqrt{x}$.

\begin{lemma}
\label{SquareRootTaylorSeries}
The Taylor series of $\sqrt{x}$ about $x_0>0$ is
\[
\sqrt{x_0} + \frac{1}{2(1!)} x_0^{-\frac{1}{2}}(x-n) + \sum_{i=2}^{\infty} \frac{(-1)^{i-1}}{2^i} \frac{1(3)(5)...(2i-3)}{i!} x_0^{-i + \frac{1}{2}}(x-x_0)^i
\]
with radius of convergence $R = x_0$.
\end{lemma}

\begin{proof}
The first few terms of the Taylor series are
\[
T(x) = \sqrt{x_0} + \frac{1}{2(1!)} x_0^{-\frac{1}{2}}(x-x_0)
- \frac{1}{2^2(2!)} x_0^{-\frac{3}{2}}(x-x_0)^2
+ \frac{3}{2^3(3!)} x_0^{-\frac{5}{2}}(x-x_0)^3 \dots
\]

To find the radius of convergence, note that
\[
\frac{1(3)(5)...(2i-3)}{2^i}
< \frac{1}{2} \left(\frac{1}{2}\right)
\left(\frac{3}{2}\right)\left(\frac{5}{2}\right)\dots \frac{2i-3}{2} 
< \frac{1}{2} 1(2)(3)\dots i
= \frac{1}{2} i!
\]
implying that when $x > x_0$,
\[
\frac{1(3)(5)...(2i-3)}{2^i(i!)} x_0^{-i + \frac{1}{2}}(x-x_0)^i
< \frac{\sqrt{x_0}}{2}\left(\frac{x}{x_0}-1\right)^i
\]
Since $T(x)$ is alternating, it converges when $\frac{x}{x_0} - 1 < 1 \rightarrow x \in [x_0, 2x_0)$.

When $x < x_0$,
\[
T(x) = \sqrt{x_0} + \frac{1}{2(1!)} x_0^{-\frac{1}{2}}(x-n) 
- \sqrt{x_0}\sum_{i=2}^{\infty} \frac{1(3)(5)...(2i-3)}{2^i(i!)} \left(1 - \frac{x}{x_0}\right)^i
\]
Since
\[
\frac{1(3)(5)...(2i-3)}{2^i(i!)} \left(1 - \frac{x}{x_0}\right)^i
< \frac{1}{2}\left(1 - \frac{x}{x_0}\right)^i
\]

and the right series is a convergent geometric series under the assumption that $x \in (0, x_0]$, $T(x)$ converges.

\end{proof}

We next show that viewed as a sequence over the natural numbers, $(g_n)$'s differences between terms become arbitrarily small.

\begin{lemma}
\label{LimitDeltaGIs0}
Let $(g_n) = 2\sqrt{2 \pi}\sqrt{n} + 1$ for $n \in N$, and $\Delta g_n = g_{n+1} - g_n = 2\sqrt{2}(\sqrt{n+1} - \sqrt{n})$. Then $\lim_{n\rightarrow\infty} \Delta g_n = 0$.
\end{lemma}

\begin{proof}
It suffices to show that $\lim_{n\rightarrow\infty} \sqrt{n+1} - \sqrt{n} = 0$. From the results in Theorem \ref{SquareRootTaylorSeries}, the Taylor series of $\sqrt{x}$ at $n$ is

\[
\sqrt{n+x} = \sqrt{n} + \frac{1}{2(1!)} n^{-\frac{1}{2}}(x) + \sum_{i=2}^{\infty} \frac{(-1)^{i-1}}{2^i} \frac{1(3)(5)...(2i-3)}{i!} n^{-i + \frac{1}{2}}(x)^i
\]

Since the series is alternating and convergent, its partial sums that have a positive term as their highest power are larger than the series. Thus

\[
\sqrt{n+1} < \sqrt{n} + \frac{1}{2\sqrt{n}}
\]

implying

\[
0 \leq \sqrt{n+1}- \sqrt{n} < \frac{1}{2\sqrt{n}}
\]

implying that $\lim_{n\rightarrow\infty} \sqrt{n+1} - \sqrt{n} = 0$.

\end{proof}

We are now in the position to prove Theorem \ref{NearCosine}.

\begin{proof}
Let $(g_n)$ be the sequence defined by $g_n = 2\sqrt{2\pi}\sqrt{n} + 1 - \pi$. Since $\lim_{n\rightarrow\infty} \Delta g_n = 0$, there exists $n_0 \in \mathbb{N}$ such that $n \geq n_0$ implies that $\Delta g_n < \delta$. This, combined with $(g_n)$ being strictly increasing and $\lim_{n\rightarrow\infty} g_n = \infty$, imply that $(g_n)$ passes through all numbers greater than $g_{n_0}$ while increasing to infinity, while taking step sizes less than $\delta$.

Specifically, for any natural number $b$ such that $2\pi b > g_{n_0}$, there exists an $a \geq n_0$ in the natural numbers such that
\[
g_a \leq 2\pi b < g_{a+1}
\]

$\Delta g_a < \delta$ implies
\[
|\Delta g_a - 2\pi b| < \delta
\]
which is equivalent to
\[
|2\sqrt{2\pi}\sqrt{a} + 1 - (2b + 1)\pi| < \delta
\]
The theorem follows because for distinct $b$, $(g_n)$ being strictly increasing implies that the $a$'s are distinct.
\end{proof}

The results of the main problem now follow.

\begin{lemma}
\label{limsupResult}
$\limsup_{n\rightarrow\infty} xf(x) = \frac{\cos(x^2))}{2} - \frac{\cos((x+1)^2)}{2} + s(x) = 1$
\end{lemma}

\begin{proof}
From Theorem \ref{NearCosine} and the continuity of $\cos(x)$, for all $\epsilon > 0$, there exist infinite $n \in \mathbb{N}$ such that $\cos(x^2) = \cos(\sqrt{2\pi n}^2) = 1$ and $|\cos\left((x+1)^2\right) + 1| = |\cos\left((\sqrt{2\pi n}+1)^2\right) + 1| < \epsilon$. As previously established, $\limsup_{x\rightarrow\infty} s(x) = 0$. 
\end{proof}

\begin{corollary}
$\liminf_{n\rightarrow\infty} xf(x) = \frac{\cos(x^2))}{2} - \frac{\cos((x+1)^2)}{2} + s(x) = -1$
\end{corollary}

\begin{proof}
Add $\pi$ to the $a$'s in Lemma \ref{limsupResult}.
\end{proof}

\subsection*{Problem 6.6:1}

On $[a, b]$, let $\alpha$ be a strictly increasing function and $f$ a continuous function, and for $x \in [a, b]$ define $F(x) = \int_a^x f(t) d\alpha(t)$. Show that for all $x \in [a, b]$, $\frac{dF(x)}{d \alpha(x)} = f(x)$, where the left-hand side is defined as $\lim_{t \to x} \frac{F(x) - F(t)}{\alpha(x) - \alpha(t)}$, and the equality includes the assertion that the limit exists.

\begin{proof}

First, we note that because $f \in \RiemannIntable(\alpha)$ on $[a, b]$

\[F(x) - F(t) = \int_a^x f(s)d\alpha(s) - \int_a^t f(s) d\alpha(s) = \int_t^x f(x) d\alpha(s)
\]

For all partitions $P$,

\begin{align*}
\int_t^x f(s) d\alpha(s)
& \leq \sum_{x_i \in P} M_i \Delta \alpha_i \\
& \leq \left(\sup_{s \in [x, t]} f(s) \right) \sum_{x_i \in P} \Delta \alpha_i \\
&= \left(\sup_{s \in [x, t]} f(s) \right) (\alpha(x) - \alpha(t))
\end{align*}

Since $\alpha(x)$ is strictly increasing, $\alpha(x) - \alpha(t) > 0$ when $x \neq t$, so

\[
\frac{F(x) - F(t)}{\alpha(x) - \alpha(t)} \leq \sup_{s \in [x, t]} f(s)
\]

Taking the limit as $t$ approaches $x$ on both sides gives

\[
\lim_{t \to x} \frac{F(x) - F(t)}{\alpha(x) - \alpha(t)} \leq \lim_{t \to x} \sup_{s \in [x, t]} f(s)
\]

\begin{lemma}

\[
\lim_{t \to x} \sup_{s \in [x, t]} f(s) = f(x)
\]

\begin{proof}

Let $x_n$ be an arbitrary sequence such that $\forall n \in \mathbb{N}, x_n > x$ and $\lim_{n \to \infty} x_n = x$. Since $[x, x_n]$ is a closed, bounded interval on $\mathbb{R}$ and $f$ is continuous, there exists a sequence of points $p_n \in [x, x_n]$ such that $f(p_n) =  \sup_{s \in [x, x_n]} f(s)$. $x_n \rightarrow x$ implies $p_n \rightarrow x$ by the Squeeze Theorem, and the continuity of $f$ implies that $f(p_n) \rightarrow f(x)$.

\end{proof}
\end{lemma}

Thus

\[
\lim_{t \to x} \frac{F(x) - F(t)}{\alpha(x) - \alpha(t)} \leq f(x)
\]

The analogous result for the lower integral and the Squeeze Theorem complete the proof.

\end{proof}

\subsection*{Problem 6.6:2}

\subsubsection*{(a)}

Show that if $f$ is continuous, then

\[
\int_{t=a}^b \left(\int_{s=a}^t f(s) ds \right) dt
= \int_{t=a}^b (b-t) f(t) dt
\]

\begin{proof}

Let $x \in [a, b]$. Define $P(x) = \int_{t=a}^x \left(\int_{s=a}^t f(s) ds \right) dt$ and $Q(x) = \int_{t=a}^x (x-t) f(t) dt$.

$f(t)$ being continuous on $[a, b]$ implies that it is Riemann-integrable. This implies that $f^*(t) = \int_{s=a}^t f(s) ds$ is continuous, and that $P(x) = \int_a^x f^*(t)dt$ is continuous and differentiable. Similarly, $(b-t)f(t)$ is continuous on $[a, b]$, so $Q(x)$ is continuous and differentiable.

By the Fundamental Theorem of Calculus,

\[
P'(x) = \int_{s=a}^x f(s) ds
\]

For $Q(x)$, since $t$ and $tf(t)$ are Riemann-integrable,

\[
Q(x) = x \int_{t=a}^x f(t) dt - \int_{t=a}^x t f(t) dt
\]

$x$ is trivially differentiable. Since $t$ and $tf(t)$ are continuous,

\[
Q'(x) = \int_{t=a}^x f(t) dt + x f(x) - x f(x) = \int_{t=a}^x f(t) dt
\]

Thus, $P'(x) = Q'(x)$. Integrating both sides from $a$ to $c$, then setting $c = b$, produces the desired result.

\end{proof}

\subsubsection*{(c)}

Show that the result of Part (a) continues to hold if $f$ is merely assumed Riemann-integrable, but not necessarily continuous.

\begin{proof}

$P(x)$ has the same derivative as in Part (a), as the derivation only assumed that $P(x)$ is Riemann-integrable. Similarly, for $x_0 \in [a, b]$ where $f(x_0)$ is continuous, the above derivations hold for $Q(x)$.

Let $x_0$ be a point where $f(x_0)$ is discontinuous. First, we will prove two lemmas.

\begin{lemma}
\label{boundedIsCont}

If $f(x)$ is bounded, then $(x - x_0) f(x)$ is continuous at $x_0$.

\begin{proof}

Let $M = \sup |f(x)|$. Then $(x - x_0) f(x) \leq |(x - x_0) f(x)| \leq |(x - x_0)| M$, which can be made arbitrarily small.

\end{proof}
\end{lemma}

\begin{lemma}
\label{contIsDiff}

If $f(x)$ is continuous, then $(x - x_0) f(x)$ is differentiable at $x_0$ with derivative $f(x_0)$.

\begin{proof}

By the definition of differentiability,

\[
\lim_{x \to x_0} \frac{(x - x_0) f(x) - (x_0 - x_0) f(x_0)}{x - x_0}
= \lim_{x \to x_0} f(x) = f(x_0)
\]

by continuity.

\end{proof}
\end{lemma}

We can rewrite $Q(x)$ as

\[
Q(x) = \int_{t=a}^x ((x-x_0) + (x_0-t)) f(t) dt
= (x-x_0) \int_{t=a}^x f(t) dt + \int_{t=a}^x (x_0-t)f(t) dt
\]

because the sub-functions are trivially Riemann-integrable. $\int_{t=a}^x f(t)$ is a continuous function, so by Lemma \ref{contIsDiff} $(x-x_0) \int_{t=a}^x f(t) dt$ is differentiable at $x = x_0$ with derivative $\int_{t=a}^{x_0} f(t) dt$. Similarly, $f(t)$ is bounded because it is Riemann-integrable, so by Lemma \ref{boundedIsCont} $(x_0-t)f(t)$ is continuous at $t = x_0$. Therefore $\int_{t=a}^x (x_0-t)f(t) dt$ is differentiable at $x = x_0$, with derivative $0$.

Therefore, $Q(x)$ is differentiable at $x = x_0$, and $Q'(x_0) = \int_{t=a}^x f(t) dt$. The proof then follows using the same logic as in Part (a).

\end{proof}

\subsection*{Problem 6.6:4}

Let $f$ be a function on $[a, b]$, and $\alpha$, $\beta$ monotonically increasing nonnegative functions on $[a, b]$ such that $f \in \RiemannIntable(\alpha) \cap \RiemannIntable(\beta)$, $\alpha \in \RiemannIntable(\beta)$, and $\beta \in \RiemannIntable(\alpha)$. Prove that

\[
\int f d(\alpha \beta) = \int f \alpha d(\beta) + \int f \beta d(\alpha)
\]

\begin{proof}

First note that $f\alpha \in \RiemannIntable(\beta)$ and $f\beta \in \RiemannIntable(\alpha)$. Also note that $\alpha\beta$ is monotonically increasing, so $\alpha\beta$ is a valid integrator.

\begin{theorem}
Under the assumptions of Problem 6.6.4, $f \in \RiemannIntable(\alpha\beta)$.
\begin{proof}

First note that by expanding the terms,
\[
\alpha_i\beta_i - \alpha_{i-1}\beta_{i-1} = (\alpha_i - \alpha_{i-1})(\beta_i - \ \beta_{i-1})
+ \alpha_{i-1}(\beta_i - \beta_{i-1}) + \beta_{i-1}(\alpha_i - \alpha_{i-1})
\]

Writing out the difference between the upper and lower Riemann sums,

\begin{align*}
& \sum_{i=1}^n (M_i - m_i)(\alpha_i\beta_i - \alpha_{i-1}\beta_{i-1}) \\
= & \sum_{i=1}^n (M_i - m_i)\Delta\alpha_i \Delta\beta_i
+ \sum_{i=1}^n (M_i - m_i)\alpha_{i-1} \Delta\beta_i
+ \sum_{i=1}^n (M_i - m_i)\beta_{i-1} \Delta\alpha_i \\
\leq 
& \alpha(b)\sum_{i=1}^n (M_i - m_i) \Delta\beta_i
+ \alpha(b)\sum_{i=1}^n (M_i - m_i) \Delta\beta_i
+ \beta(b)\sum_{i=1}^n (M_i - m_i) \Delta\alpha_i
\end{align*}

The third line follows because all terms are positive, and $\alpha$ and $\beta$ are monotonically increasing. Because $f \in \RiemannIntable(\alpha)\cap \RiemannIntable(\beta)$, there exist partitions that make the third line arbitrarily small.

\end{proof}
\end{theorem}

Now we prove the main result. For arbitrary $\epsilon > 0$, let $P_1$, $P_2$, and $P_3$ be partitions of $[a, b]$ such that

\begin{enumerate}
\item $U(P_1, f, \alpha\beta) - L(P_1, f, \alpha\beta) < \epsilon$
\item $U(P_2, f\alpha, \beta) - L(P_2, f\alpha, \beta) < \epsilon$
\item $U(P_3, f\beta, \alpha) - L(P_3, f\beta, \alpha) < \epsilon$
\end{enumerate}

Let $P$ be their common partition. Let $x_0 < x_1 ... < x_n$ denote the points of $P$. For all $i$ in $(1, 2...n)$, let $t_i \in (x_{i-1}, x_i)$ be arbitrary, fixed points, and let $P^* = (x_0, t_1, x_1 ... x_{i-1}, t_i, x_i ... t_n, x_n)$. Trivially, $P^*$ partitions $[a, b]$ and is a refinement of $P$.

Consider $\int f d(\alpha\beta)$ and its associated Riemann-Stieltjes sum over $P^*$. Since $P^*$ is a refinement of $P_1$, for arbitrary points $u_i \in [x_{i-1}, t_i]$ and $v_i \in [t_i, x_i]$,

\[
\abs*{ \sum_{i=1}^n \left[f(u_i)(\alpha_{t_i}\beta_{t_i} - \alpha_{x_{i-1}}\beta_{x_{i-1}})
+ f(v_i)(\alpha_{x_i}\beta_{x_i} - \alpha_{t_i}\beta_{t_i})\right]
- \int f d(\alpha\beta)}
< \epsilon
\]

Letting $u_i = x_{i-1}$ and $v_i = x_i$ for all $i$,

\[
\abs*{ \sum_{i=1}^n \left[f_{x_{i-1}}(\alpha_{t_i}\beta_{t_i} - \alpha_{x_{i-1}}\beta_{x_{i-1}})
+ f_{x_i}(\alpha_{x_i}\beta_{x_i} - \alpha_{t_i}\beta_{t_i})\right]
- \int f d(\alpha\beta)}
< \epsilon
\]

Now consider $\int f\alpha d(\beta)$ and its associated Riemann-Stieltjes sum over $P$. Letting $u_i = x_i$ for all $i$,

\[
\abs*{ \sum_{i=1}^n \left[f_{x_i}\alpha_{x_i}(\beta_{x_i} - \beta_{x_{i-1}})\right]
- \int f\alpha d(\beta)}
< \epsilon
\]

Similarly, considering $\int f\beta d(\alpha)$ over $P$ and letting $u_i = x_{i-1}$ for all $i$,

\[
\abs*{ \sum_{i=1}^n \left[f_{x_{i-1}}\beta_{x_{i-1}}(\alpha_{x_i} - \alpha_{x_{i-1}})\right]
- \int f\beta d(\alpha)}
< \epsilon
\]

Adding the inequalities and using the Triangle Inequality gives

\begin{gather*}
\bigg|
\int f d(\alpha\beta) - \int f\alpha d(\beta) - \int f\beta d(\alpha) \\
+ \sum_{i=1}^n \Big[
-\left[f_{x_{i-1}}(\alpha_{t_i}\beta_{t_i} - \alpha_{x_{i-1}}\beta_{x_{i-1}})
+ f_{x_i}(\alpha_{x_i}\beta_{x_i} - \alpha_{t_i}\beta_{t_i}) \right] \\
+ f_{x_i}\alpha_{x_i}(\beta_{x_i} - \beta_{x_{i-1}})
+ f_{x_{i-1}}\beta_{x_{i-1}}(\alpha_{x_i} - \alpha_{x_{i-1}})
\Big] \bigg|
< 3\epsilon
\end{gather*}

Simplifying,

\[
\bigg|
\int f d(\alpha\beta) - \int f\alpha d(\beta) - \int f\beta d(\alpha) +
\sum_{i=1}^n \Big[
(f_{x_i} - f_{x_{i-1}}) (\alpha_{t_i}\beta_{t_{i-1}} - \alpha_{x_i}\beta_{x_{i-1}})
\Big] \bigg|
< 3\epsilon
\]

To analyze the sum on the right, note that

\begin{align*}
\bigg|
&\sum_{i=1}^n \Big[(f_{x_i} - f_{x_{i-1}}) (\alpha_{t_i}\beta_{t_{i-1}} - \alpha_{x_i}\beta_{x_{i-1}})
\bigg| \\
\leq &\sum_{i=1}^n \left|f_{x_i} - f_{x_{i-1}}\right| \left|\alpha_{t_i}\beta_{t_{i-1}} - \alpha_{x_i}\beta_{x_{i-1}}\right| \\
\leq &\sum_{i=1}^n \left(\sup_{x \in [x_{i-1}, x_i]} f(x) - \inf_{x \in [x_{i-1}, x_i]} f(x)\right)
\left(\alpha_{x_i}\beta_{x_i} - \alpha_{x_{i-1}}\beta_{x_{i-1}}\right) \\
< &\epsilon
\end{align*}

The second inequality comes from noticing that $t_i$ is in $(x_{i-1}, x_i)$, and that $\alpha\beta$ is weakly increasing. The third inequality comes from $P$ being a refinement of $P_1$. Thus

\[
\bigg| \int f d(\alpha\beta) - \int f\alpha d(\beta) - \int f\beta d(\alpha) \bigg|
< 4\epsilon
\]

Which can be made arbitrarily close to 0.

\end{proof}

\end{document}